# Portfolio Data Clearinghouse

Welcome to the Portfolio Data Clearinghouse. This is a high-performance backend system designed to ingest messy financial data from recognized sources (SFTP), normalize it into a clean relational schema, and expose it via a secure JSON API.

It's built with **Go** for speed and type safety, **PostgreSQL** for reliable data storage, and **OpenTofu** for modern, declarative infrastructure on AWS.

---

## ÔøΩÔ∏è Architecture

```mermaid
graph TD
    Client[Client/User] -->|HTTPS / API Key| ALB[Load Balancer / Ingress]
    ALB -->|Port 8080| App[Go App (ECS Fargate)]
    
    subgraph "VPC (Private Network)"
        App -->|Port 5432| DB[(AWS RDS Postgres)]
        App -->|Localhost:22| SFTP[SFTP Sidecar]
    end
    
    SFTP -->|Uploads| Volume[Shared Volume]
    
    subgraph "Monitoring"
        CW[CloudWatch] -->|CPU Alarm| SNS[SNS Topic]
        SNS -->|Email| User[User Email]
    end
    
    App --> CW
```

## ÔøΩüéØ Requirements & Implementation

### 1. Data Ingestion
**Requirement:** *Ingest files of two different formats into a single relational database table from an FTP server.*

**Delivered:**
*   **Source:** A secure SFTP sidecar container (`atmoz/sftp`) running alongside the app.
*   **The Engine:** A robust Go background worker (`internal/ingest`) that watches the upload directory.
*   **Normalization:**
    *   **Format 1 (CSV)**: Parsed as "Trade Flow" (deltas).
    *   **Format 2 (Pipe)**: Parsed as "Daily Snapshot".
    *   **Unified Schema:** Both formats are normalized into a single `positions` table keyed by `(date, account_id, ticker)`. The system handles upserts automatically, so you can re-process files without duplicate data issues.

### 2. API Endpoints
**Requirement:** *Expose data via HTTP API.*

**Delivered:**
*   `GET /blotter`: A unified view of all trades and positions for a specific date.
*   `GET /positions`: Calculates portfolio allocations dynamically. Returns the percentage of the portfolio each holding represents.
*   `GET /alarms`: A compliance check that flags any account where a SINGLE holding exceeds **20%** of the total portfolio value.

### 3. Infrastructure & DevOps
**Requirement:** *Cloud-ready, automated, and observable.*

**Delivered:**
*   **IaC**: 100% defined in **OpenTofu** (Terraform compatible). No "ClickOps".
*   **Compute**: Runs on **AWS Fargate** (Serverless ECS). No servers to manage.
*   **Database**: Managed **AWS RDS (PostgreSQL 18.1)**.
*   **CI/CD**: A GitHub Actions pipeline that builds, tests, pushes to ECR, and deploys to AWS automatically on every commit to `main`.

---

## üõ°Ô∏è Security Features (The "Extra Mile")

We didn't just build it to work; we built it to be secure.

1.  **Network Isolation**: The Database is LOCKED DOWN. It runs in a secure VPC and only accepts traffic on port 5432 from the Application's specific Security Group. It is not accessible from the public internet.
2.  **API Authentication**: All endpoints are protected by a Pre-Shared Key (Verified via `X-API-Key` header).
3.  **Secrets Management**: Database passwords are never hardcoded. They are generated by Terraform and stored in **AWS Secrets Manager**. The app retrieves them at runtime.
4.  **Rootless Containers**: The Docker image runs as a non-privileged user (`appuser`, UID 1001) to minimize the attack surface.

---

## üöÄ How to Run

### Local Development
You can spin up the entire stack locally using Docker Compose:

```bash
docker-compose up --build
```

This will start:
*   Postgres (db)
*   SFTP Server (sftp)
*   Go API Server (api)

Test it with curl:
```bash
# Health Check
curl http://localhost:8080/health

# Check Blotter (Auth required if configured, local default allows relaxed dev mode if env var missing, but production enforces it)
curl -H "X-API-Key: local-dev-key" "http://localhost:8080/blotter?date=2025-01-15"
```

### Deployment
Deployment is fully automated via GitHub Actions.
1.  Push to `main`.
2.  Grab a coffee. ‚òï
3.  The pipeline will:
    *   Run Unit Tests.
    *   Build & Dockerize.
    *   Applying OpenTofu Infrastructure.
    *   **Verify**: It runs a live `smoketest.sh` against the deployed cloud endpoints to guarantee success.

---

## üìä Monitoring & Observability

*   **Logs**: Structured application logs stream to CloudWatch Logs.
*   **Alerting**: A CloudWatch Alarm watches **ECS CPU** and **RDS CPU**. If either exceeds **80%**, an SNS alert is triggered (email subscription configured).

---

*Built by Andrew Hay using Go/OpenTofu.*
